## 🚀 Overview

**Basic-LLM-Project** is an innovative developer tool that combines large language models with a user-friendly web interface, enabling seamless multimodal AI interactions like:

- 💬 Natural language chat
- 📄 PDF-based question answering
- 🌐 Real-time web-based search (e.g., weather)

Built using **NVIDIA Neva-22B**, **LangChain**, and **Streamlit**, it simplifies deploying, managing, and customizing powerful AI workflows in a modular, plug-and-play architecture.

---

## 📦 Built With

- Python 🐍
- Markdown 📄
- LangChain ⚙️
- NVIDIA Neva-22B 🧠
- Streamlit 🌐

---

## 📚 Features

- 🧩 **Chat & Q&A:** Converse with the model via text and answer document-based questions.
- 🌐 **Web Search Integration:** Get live data like weather, news, etc., inside the chat.
- ⚙️ **Custom Model Calls:** Build your own AI tasks using model chaining.
- 📄 **Document Support:** Upload PDFs and query them intelligently.
- 🚀 **Streamlined Architecture:** Rapid deployment and easy extensibility.

---

## 🛠 Getting Started

### ✅ Prerequisites

- Python (≥3.8)
- Conda (recommended)

---

### 🧰 Installation

```bash
# 1. Clone the repository
git clone https://github.com/RupeshJ98/Basic-LLM-Project

# 2. Navigate into the directory
cd Basic-LLM-Project

# 3. Install dependencies via Conda
conda env create -f conda.yml
